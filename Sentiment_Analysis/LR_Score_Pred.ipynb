{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea011ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import emoji\n",
    "import regex\n",
    "import string\n",
    "from datetime import timedelta\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from unidecode import unidecode as unidec\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a73e8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_=\"C:\\\\Users\\\\Alex\\\\Personal-Code\\\\ACE_592_Dating_Sim\\\\Wrangled_Data\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef16d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads the csv files into memory for each dating app.\n",
    "#Data has already been cleaed and all three files share the same columns\n",
    "df_T = pd.read_csv(dir_ + \"sent_Tinder.csv\")\n",
    "df_T = df_T[['userName', 'full_text','clean_text', 'score', 'comp_sent', 'neg_sent', 'pos_sent', 'neu_sent', 'word_count']]\n",
    "\n",
    "df_B = pd.read_csv(dir_ + \"sent_Bumble.csv\")\n",
    "df_B = df_B[['userName', 'full_text','clean_text', 'score', 'comp_sent', 'neg_sent', 'pos_sent', 'neu_sent', 'word_count']]\n",
    "\n",
    "df_H = pd.read_csv(dir_ + \"sent_Hinge.csv\")\n",
    "df_H = df_H[['userName', 'full_text','clean_text', 'score', 'comp_sent', 'neg_sent', 'pos_sent', 'neu_sent', 'word_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f22254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_T.head(5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2745de2c",
   "metadata": {},
   "source": [
    "### Let's analyze these features before we start trying to train a model. Starting with Corr Coeff's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ce69bc",
   "metadata": {},
   "source": [
    "#### Tinder Correlation Coeff's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d278c4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>comp_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.592181</td>\n",
       "      <td>-0.436198</td>\n",
       "      <td>0.620673</td>\n",
       "      <td>-0.411952</td>\n",
       "      <td>-0.398247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp_sent</th>\n",
       "      <td>0.592181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.630197</td>\n",
       "      <td>0.657123</td>\n",
       "      <td>-0.319293</td>\n",
       "      <td>-0.213057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_sent</th>\n",
       "      <td>-0.436198</td>\n",
       "      <td>-0.630197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.387802</td>\n",
       "      <td>-0.173846</td>\n",
       "      <td>0.025361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_sent</th>\n",
       "      <td>0.620673</td>\n",
       "      <td>0.657123</td>\n",
       "      <td>-0.387802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.816623</td>\n",
       "      <td>-0.331127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu_sent</th>\n",
       "      <td>-0.411952</td>\n",
       "      <td>-0.319293</td>\n",
       "      <td>-0.173846</td>\n",
       "      <td>-0.816623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.348570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>-0.398247</td>\n",
       "      <td>-0.213057</td>\n",
       "      <td>0.025361</td>\n",
       "      <td>-0.331127</td>\n",
       "      <td>0.348570</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               score  comp_sent  neg_sent  pos_sent  neu_sent  word_count\n",
       "score       1.000000   0.592181 -0.436198  0.620673 -0.411952   -0.398247\n",
       "comp_sent   0.592181   1.000000 -0.630197  0.657123 -0.319293   -0.213057\n",
       "neg_sent   -0.436198  -0.630197  1.000000 -0.387802 -0.173846    0.025361\n",
       "pos_sent    0.620673   0.657123 -0.387802  1.000000 -0.816623   -0.331127\n",
       "neu_sent   -0.411952  -0.319293 -0.173846 -0.816623  1.000000    0.348570\n",
       "word_count -0.398247  -0.213057  0.025361 -0.331127  0.348570    1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCorrT = df_T[['score', 'comp_sent', 'neg_sent', 'pos_sent', 'neu_sent', 'word_count']]\n",
    "dfCorrT.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6a66b8",
   "metadata": {},
   "source": [
    "Tinder: Seems like comp_sent, neg_sent, and pos_sent all do pretty well. WC and Neu aren't bad either. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f344767d",
   "metadata": {},
   "source": [
    "#### Bumble Correlation Coeff's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e0b5ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>comp_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.553421</td>\n",
       "      <td>-0.401492</td>\n",
       "      <td>0.607021</td>\n",
       "      <td>-0.409056</td>\n",
       "      <td>-0.352153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp_sent</th>\n",
       "      <td>0.553421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.592264</td>\n",
       "      <td>0.594590</td>\n",
       "      <td>-0.266427</td>\n",
       "      <td>-0.101167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_sent</th>\n",
       "      <td>-0.401492</td>\n",
       "      <td>-0.592264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.366426</td>\n",
       "      <td>-0.199817</td>\n",
       "      <td>-0.012719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_sent</th>\n",
       "      <td>0.607021</td>\n",
       "      <td>0.594590</td>\n",
       "      <td>-0.366426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.814790</td>\n",
       "      <td>-0.337786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu_sent</th>\n",
       "      <td>-0.409056</td>\n",
       "      <td>-0.266427</td>\n",
       "      <td>-0.199817</td>\n",
       "      <td>-0.814790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>-0.352153</td>\n",
       "      <td>-0.101167</td>\n",
       "      <td>-0.012719</td>\n",
       "      <td>-0.337786</td>\n",
       "      <td>0.372264</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               score  comp_sent  neg_sent  pos_sent  neu_sent  word_count\n",
       "score       1.000000   0.553421 -0.401492  0.607021 -0.409056   -0.352153\n",
       "comp_sent   0.553421   1.000000 -0.592264  0.594590 -0.266427   -0.101167\n",
       "neg_sent   -0.401492  -0.592264  1.000000 -0.366426 -0.199817   -0.012719\n",
       "pos_sent    0.607021   0.594590 -0.366426  1.000000 -0.814790   -0.337786\n",
       "neu_sent   -0.409056  -0.266427 -0.199817 -0.814790  1.000000    0.372264\n",
       "word_count -0.352153  -0.101167 -0.012719 -0.337786  0.372264    1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCorrB = df_B[['score', 'comp_sent', 'neg_sent', 'pos_sent', 'neu_sent', 'word_count']]\n",
    "dfCorrB.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab2c96",
   "metadata": {},
   "source": [
    "Bumble: Seems like comp_sent, neg_sent, and pos_sent all do pretty well. WC and Neu aren't bad either. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1948f22c",
   "metadata": {},
   "source": [
    "#### Hinge Correlation Coeff's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b94187d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>comp_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.579121</td>\n",
       "      <td>-0.433791</td>\n",
       "      <td>0.568955</td>\n",
       "      <td>-0.369662</td>\n",
       "      <td>-0.320747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp_sent</th>\n",
       "      <td>0.579121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.614840</td>\n",
       "      <td>0.582003</td>\n",
       "      <td>-0.273129</td>\n",
       "      <td>-0.069998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_sent</th>\n",
       "      <td>-0.433791</td>\n",
       "      <td>-0.614840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.371972</td>\n",
       "      <td>-0.154061</td>\n",
       "      <td>0.024648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_sent</th>\n",
       "      <td>0.568955</td>\n",
       "      <td>0.582003</td>\n",
       "      <td>-0.371972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.846222</td>\n",
       "      <td>-0.363301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu_sent</th>\n",
       "      <td>-0.369662</td>\n",
       "      <td>-0.273129</td>\n",
       "      <td>-0.154061</td>\n",
       "      <td>-0.846222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.378323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>-0.320747</td>\n",
       "      <td>-0.069998</td>\n",
       "      <td>0.024648</td>\n",
       "      <td>-0.363301</td>\n",
       "      <td>0.378323</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               score  comp_sent  neg_sent  pos_sent  neu_sent  word_count\n",
       "score       1.000000   0.579121 -0.433791  0.568955 -0.369662   -0.320747\n",
       "comp_sent   0.579121   1.000000 -0.614840  0.582003 -0.273129   -0.069998\n",
       "neg_sent   -0.433791  -0.614840  1.000000 -0.371972 -0.154061    0.024648\n",
       "pos_sent    0.568955   0.582003 -0.371972  1.000000 -0.846222   -0.363301\n",
       "neu_sent   -0.369662  -0.273129 -0.154061 -0.846222  1.000000    0.378323\n",
       "word_count -0.320747  -0.069998  0.024648 -0.363301  0.378323    1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCorrH = df_H[['score', 'comp_sent', 'neg_sent', 'pos_sent', 'neu_sent', 'word_count']]\n",
    "dfCorrH.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa35f0db",
   "metadata": {},
   "source": [
    "Hinge: Seems like comp_sent, neg_sent, and pos_sent all do pretty well. WC and Neu aren't bad either. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bf22cc",
   "metadata": {},
   "source": [
    "### Lasso Regression for Feature Analysis. Yeehaw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e22b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df):\n",
    "    df_data = df[['score', 'comp_sent', 'neg_sent', 'pos_sent', 'neu_sent', 'word_count']]\n",
    "    df_data = df_data.loc[df_data['score'] != 0]\n",
    "\n",
    "    #all missing data has already been removed. There should be no need to account for it here\n",
    "    x = df_data[['comp_sent', 'pos_sent', 'word_count','neg_sent', 'neu_sent']]\n",
    "    y = df_data['score']\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c514593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.          0.         -0.         -0.00655698]\n"
     ]
    }
   ],
   "source": [
    "#tinder\n",
    "x, y = get_data(df_T)\n",
    "lasso_model = Lasso(max_iter= -1)\n",
    "lasso_model.fit(x,y)\n",
    "# model_lasso.n_features_in_\n",
    "# print(model_lasso.feature_names_in_)\n",
    "print(lasso_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee5a65fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.          0.         -0.         -0.00451427]\n"
     ]
    }
   ],
   "source": [
    "#bumble\n",
    "x, y = get_data(df_B)\n",
    "lasso_model = Lasso(max_iter= -1)\n",
    "lasso_model.fit(x,y)\n",
    "# model_lasso.n_features_in_\n",
    "# print(model_lasso.feature_names_in_)\n",
    "print(lasso_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5891b547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.          0.         -0.         -0.00449937]\n"
     ]
    }
   ],
   "source": [
    "#Hinge\n",
    "x, y = get_data(df_H)\n",
    "lasso_model = Lasso(max_iter= -1)\n",
    "lasso_model.fit(x,y)\n",
    "# model_lasso.n_features_in_\n",
    "# print(model_lasso.feature_names_in_)\n",
    "print(lasso_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a91dead",
   "metadata": {},
   "source": [
    "#### Hmmmmmm. This didn't yield quite the results I was hoping for. I'll probably just try building the model with Grid Search using all of the data points and then go from there. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597e748f",
   "metadata": {},
   "source": [
    "## Logistic Regression for predicting Tinder Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb2a13",
   "metadata": {},
   "source": [
    "### Change Log:\n",
    "\n",
    "- First iteration of model uses all available features to train the model for Tinder. The model parameters were detemined using a grid search. Optimal parameters determined to be: A model is then trained with the optimal params using stratified k-fold CV cv = 10. Model outputs an accuracy of 0.675207. Best Params = {'C': 10, 'class_weight': None, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "- Second iteration running with only 'comp_sent', 'pos_sent', 'word_count'. Optimized Total Accuracy = 0.6584194527589127. Best Params = {'C': 1, 'class_weight': None, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'lbfgs'}. So we shall use all features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b7673ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy = 0.6584194527589127\n",
      "Best Params = {'C': 1, 'class_weight': None, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(LogisticRegression(multi_class='multinomial', n_jobs=-1, max_iter=200000), {\n",
    "    'C' : [1, 10, 25],\n",
    "    'penalty' : ['l2', 'none'],\n",
    "    'class_weight' : [None, 'balanced'],\n",
    "    'solver' : ['newton-cg', 'lbfgs'],\n",
    "    'fit_intercept' : [True, False]\n",
    "}, cv = 5, return_train_score=False)\n",
    "\n",
    "#change your data resolution here \n",
    "x, y = get_data(df_T)\n",
    "\n",
    "# #checks available input parameter keys as a test case\n",
    "# clf.get_params().keys()\n",
    "\n",
    "#calls the fit function to actually do the thing on the training data\n",
    "clf.fit(x,y)\n",
    "\n",
    "print(\"Total Accuracy = \" + str(clf.best_score_))\n",
    "print(\"Best Params = \" + str(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76e0642a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.658419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.658413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.658413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.658413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.657728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.657728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.657728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.657728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.657728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.657725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_class_weight param_penalty param_solver  mean_test_score\n",
       "1        1               None            l2        lbfgs         0.658419\n",
       "3        1               None          none        lbfgs         0.658413\n",
       "19      10               None          none        lbfgs         0.658413\n",
       "35      25               None          none        lbfgs         0.658413\n",
       "32      25               None            l2    newton-cg         0.657728\n",
       "2        1               None          none    newton-cg         0.657728\n",
       "18      10               None          none    newton-cg         0.657728\n",
       "16      10               None            l2    newton-cg         0.657728\n",
       "34      25               None          none    newton-cg         0.657728\n",
       "17      10               None            l2        lbfgs         0.657725"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calls the results and puts them into a dataframe\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "df1 = df[['param_C', 'param_class_weight', 'param_penalty', 'param_solver', 'mean_test_score']] #, 'param_ccp_alpha'\n",
    "df1.sort_values('mean_test_score', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3807da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets x and y data, and then splits that data into training and testing data\n",
    "x, y = get_data(df_T)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, shuffle=True)\n",
    "\n",
    "model= LogisticRegression(C=10, penalty = 'l2', solver = 'lbfgs', multi_class='multinomial', n_jobs=4, max_iter=200000)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)\n",
    "\n",
    "fold= StratifiedKFold(n_splits=10, shuffle=True)\n",
    "y_predict = cross_val_predict(model,x,y,cv=fold)\n",
    "cm_1 = confusion_matrix(y_predict,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034dde2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdd5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reused code for the confusion matrix\n",
    "cmap= sn.cubehelix_palette(light=0.98, dark=0.15, n_colors=20)\n",
    "# cm_1 = confusion_matrix(y_pred,y_test)\n",
    "df_cm = pd.DataFrame(cm_1.T, range(5), range(5))\n",
    "plt.figure(figsize=(12,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "ax= plt.subplot()\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},cmap=cmap, fmt='d',ax=ax) # font size\n",
    "ax.set_xlabel('Predicted values');ax.set_ylabel('Actual values'); \n",
    "ax.set_title('Confusion Matrix -Tinder Logistic Regression');\n",
    "ax.xaxis.set_ticklabels(['1', '2', '3', '4', '5']); \n",
    "ax.yaxis.set_ticklabels(['1', '2', '3', '4', '5'])\n",
    "#plt.savefig(\"D:\\\\CM1-kfold.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6308ac43",
   "metadata": {},
   "source": [
    "#### Assuming that the optimal params are the same for all sets, we will train the Hinge and Bumble Models using the same params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31a6e0",
   "metadata": {},
   "source": [
    "### Bumble MLR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1122b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets x and y data, and then splits that data into training and testing data\n",
    "x, y = get_data(df_B)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, shuffle=True)\n",
    "\n",
    "model= LogisticRegression(C=10, penalty = 'l2', solver = 'lbfgs', multi_class='multinomial', n_jobs=-1, max_iter=200000)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)\n",
    "\n",
    "fold= StratifiedKFold(n_splits=10, shuffle=True)\n",
    "y_predict = cross_val_predict(model,x,y,cv=fold)\n",
    "cm_2 = confusion_matrix(y_predict,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37553be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reused code for the confusion matrix\n",
    "cmap= sn.cubehelix_palette(light=0.98, dark=0.15, n_colors=20)\n",
    "# cm_1 = confusion_matrix(y_pred,y_test)\n",
    "df_cm = pd.DataFrame(cm_2.T, range(5), range(5))\n",
    "plt.figure(figsize=(12,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "ax= plt.subplot()\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},cmap=cmap, fmt='d',ax=ax) # font size\n",
    "ax.set_xlabel('Predicted values');ax.set_ylabel('Actual values'); \n",
    "ax.set_title('Confusion Matrix - Bumble Logistic Regression');\n",
    "ax.xaxis.set_ticklabels(['1', '2', '3', '4', '5']); \n",
    "ax.yaxis.set_ticklabels(['1', '2', '3', '4', '5'])\n",
    "#plt.savefig(\"D:\\\\CM1-kfold.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703829ff",
   "metadata": {},
   "source": [
    "### Hinge MLR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc867be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets x and y data, and then splits that data into training and testing data\n",
    "x, y = get_data(df_H)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, shuffle=True)\n",
    "\n",
    "model= LogisticRegression(C=10, penalty = 'l2', solver = 'lbfgs', multi_class='multinomial', n_jobs=-1, max_iter=200000)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)\n",
    "\n",
    "fold= StratifiedKFold(n_splits=10, shuffle=True)\n",
    "y_predict = cross_val_predict(model,x,y,cv=fold)\n",
    "cm_3 = confusion_matrix(y_predict,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ad09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdd9141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reused code for the confusion matrix\n",
    "cmap= sn.cubehelix_palette(light=0.98, dark=0.15, n_colors=20)\n",
    "# cm_1 = confusion_matrix(y_pred,y_test)\n",
    "df_cm = pd.DataFrame(cm_3.T, range(5), range(5))\n",
    "plt.figure(figsize=(12,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "ax= plt.subplot()\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},cmap=cmap, fmt='d',ax=ax) # font size\n",
    "ax.set_xlabel('Predicted values');ax.set_ylabel('Actual values'); \n",
    "ax.set_title('Confusion Matrix - Hinge Logistic Regression');\n",
    "ax.xaxis.set_ticklabels(['1', '2', '3', '4', '5']); \n",
    "ax.yaxis.set_ticklabels(['1', '2', '3', '4', '5'])\n",
    "#plt.savefig(\"D:\\\\CM1-kfold.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
